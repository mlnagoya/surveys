# Knowing Ourselves Through Others: Reflecting with AI in Digital Human Debates
https://arxiv.org/abs/2511.13046
(まとめ @n-kats)

## 著者
- Ichiro Matsuda
- Komichi Takezawa
- Katsuhito Muroi
- Kensuke Katori
- Ryosuke Hyakuta
- Jingjing Li
- Yoichi Ochiai

![図1 想定: デジタルヒューマン・デベートの全体像](./reflecting_with_ai_2511.13046/fig1_dhd_overview_placeholder.png)

# どんなもの？
- 個人の価値観や話し方を反映した「デジタルヒューマン（個人化LLM）」同士にディベートをさせ、その様子を人間が観察することで、自己理解や思考の客観視（リフレクション）がどこまで促進されるかを探った研究。
- まず研究室メンバーを対象に、人間そっくりのマルチモーダル・デジタルヒューマンとの対話実験（パイロットスタディ）を行い、AIがディベート相手として成立するかと、自己投影したデジタルヒューマンを「他者」と感じる心理的距離を検証。
- そのうえで、中高生9名（3チーム）が6か月かけて自分たちのデジタルヒューマンを設計・実装し、それらにディベート大会（Digital Human Debates Contest）をさせる「Research through Design」型の本実験を実施。
- 生成AIリテラシーテスト（GLAT）、インタビュー、ログ分析を通じて、参加者がAIの能力理解だけでなく、「自分の思考の偏り・論理の弱さ」をAIを鏡として振り返る新しいリテラシー「Reflecting with AI」を提案。

# 先行研究と比べてどこがすごい？
- IBM Project Debater や AI Safety via Debate など、AI同士の議論を用いた信頼性向上・安全性向上の研究は多数あるが、本研究は「パーソナライズされたデジタルヒューマン同士の議論を、人間が観察する経験」にフォーカスしている点が新しい。
- 既存のAIリテラシー／生成AIリテラシー研究は「ツールとしてのAIの理解・活用・評価・倫理」を軸にしてきたのに対し、本研究は「AIを通して自分自身をどう振り返るか」というメタ認知的な能力をリテラシーとして位置づける。
- 中高生が自らプロンプト設計・RAGドキュメント作成・ペルソナ設計を行い、その成果物としてのデジタルヒューマンの議論を長期にわたり設計・観察する実践的なフレームワークを提示しており、12の生成AIリテラシー・コンピテンシーを包括的にカバーしている。
- デジタルヒューマンが「自分の過去経験や価値観を反映しつつ、自分の手を離れて勝手に議論する他者」として知覚される心理的距離を丁寧に記述し、自己観察の難しさをAI媒介でどこまでクリアできるかを示している。

![図2 想定: デジタルヒューマン生成とディベートのプロセス図](./reflecting_with_ai_2511.13046/fig2_pipeline_placeholder.png)

# 技術や手法の肝は？
- デジタルヒューマン基盤
  - GPT-4 Turbo / GPT-4o を中核とし、RAG による外部知識参照、Google Cloud Text-to-Speech による音声合成、Wav2Lip と音声変換（RVC）によるリップシンク動画生成を組み合わせたマルチモーダル対話エージェント。
  - 音声認識や応答生成、音声・映像出力までを一連に扱うサンプルコードをGitHubで提供し、高校生でも改変・拡張できるようにしたアーキテクチャ設計。
- 生徒がカスタマイズする3つのドキュメント
  - `system_prompt_template.txt`：ディベートのルール、推論の制約、論証戦略などを記述し、出力の論理構造や立場表明の仕方を制御。
  - `interview_transcript.txt`：インタビュー形式で、個人史・価値観・話し方などのペルソナ情報を記述し、「誰のデジタルヒューマンか」を表現。
  - `Documents`：肯定／否定両サイドの根拠資料を格納するRAG用ドキュメント群。議論の材料や証拠の質に直結。
- デジタルヒューマン・デベート（DHD）の設計
  - トピック（高齢者の免許返納、リモートワーク、安楽死、ベーシックインカム）ごとに、肯定・否定それぞれのデジタルヒューマンを事前に設計。
  - 本番の対戦では、ルーレットでトピックと立場をランダムに決定し、各チームは用意していた8体のデジタルヒューマンから適切な組み合わせを選択する。
  - ディベート形式は日本の高校生大会の形式に準拠し、立論・反駁・クロスエグザミネーション・最終弁論などを約20分で実施。

# どうやって有効だと検証した？
- パイロットスタディ（研究室メンバー12名）
  - 参加者1人ひとりのペルソナ情報（個人史・価値観・口調）、音声・顔画像を収集し、自身を模したマルチモーダル・デジタルヒューマンを構築。
  - 人間同士、相手のデジタルヒューマン、自己のデジタルヒューマンの3条件でディベートを行い、PANAS（感情状態）とNASA-TLX（メンタルワークロード）、システム評価アンケートを比較。
  - 結果として、デジタルヒューマンは感情負荷・負担の面で人間と同等レベルで機能しつつ、「自己のデジタルヒューマン」については人格再現度の評価がやや低く、インタビューから「自分なのに自分ではない他者」として知覚されていることが示唆された。
- 本実験：Digital Human Debates Contest（中高生9名）
  - 3チーム（各3名、プログラミング・ディベート経験はばらばら）が6か月間、オンラインミーティングやDiscordでの伴走支援を受けながらデジタルヒューマンを設計・実装。
  - コンテスト当日は3試合の総当たり戦を行い、外部研究者を含む3名のジャッジが、技術的完成度・論理の一貫性・エンタメ性などを総合評価。
  - 定量評価として、参加者9名と同学年の非参加者12名に日本語版GLAT（20問）を実施し、問題ごとの正答率および4カテゴリ（Know & Understand / Use & Apply / Evaluate & Create / Ethics）の平均正答率を比較。
  - 定性評価として、参加者・教師・ジャッジへのインタビュー、開発ログ、デベートの映像やトランスクリプト、プロンプト・コードのバージョン履歴を分析。
- 結果の概要
  - GLATでは、全体として参加者の方が多くの設問で高い正答率を示し、とくに生成AIの仕組みやリスクに関する問題で優位な傾向が見られた（有意差は問題によってばらつきあり）。
  - 質的データでは、参加者が「自分は普段、衝動的に話していて論理が弱いと気づいた」「AIの発言を見ながら、自分ならどう言い換えるかを常に考えるようになった」といったメタ認知的な変化を一貫して報告。

# 議論はある？
- Reflecting with AI という新しいリテラシー
  - 参加者は、自分が作ったデジタルヒューマンの議論を観察することで、「これは本当に自分が言いたいことか？」「論理のつなぎ方は適切か？」を客観的に検証できたと述べている。
  - 自分自身の録画を見返す自己観察は「恥ずかしさ」が邪魔をして難しい一方、AIが自分のデータから生成した発話であれば、適度な心理的距離のおかげで冷静に批判・振り返りができる。
  - 著者らは、従来の「理解する・使う・評価する・倫理を考える」に加えて、「AIを媒介として自己を再検討する」能力を生成AIリテラシーの追加コンピテンシーと位置づけている。
- 論理の弱点や準備不足の可視化
  - 参加者はAIのディベートを見ながら、「この論点は証拠が薄い」「この話題は資料の準備が足りなかった」といった具体的な弱点に気づき、次の準備やプロンプト修正に反映している。
  - 特に、あるチームは歴史上の人物をペルソナにし、ChatGPTに自分たちのプロンプトを評価させ、そのフィードバックをそのままプロンプトに組み込むなど、AI同士のメタ的な評価ループを構築していた。
  - 別のチームは、RAGドキュメントにほぼ完成された立論原稿を入れ、「AIは論理のメッセンジャー」として位置づける戦略を取っており、AIへの自己投影の仕方の違いが比較されている。
- 限界と今後
  - サンプルサイズは小さく、学校・文化的背景も限定されているため、GLATの効果検証としては探索的段階にとどまる。
  - 参加者はモチベーションの高い中高生であり、一般的な学習者に同様の効果が見られるかは今後の検証課題。
  - デジタルヒューマンが作り手のバイアスや情報の偏りをそのまま増幅するリスクもあり、「Reflecting with AI」が自己肯定バイアスの強化や思考停止につながらないような設計原則が必要。

## 私見
- 「AIをうまく使う」から一歩進んで、「AIを鏡として自分の思考や価値観を振り返る」という観点を明示的にリテラシーとして定義している点が、教育実践・ツール設計の両面で非常に示唆的に感じた。
- 特に、自己そっくりのデジタルヒューマンを直接操作するのではなく、あくまで「手を離して観察する」体験としてデザインしているところが上手く、メタ認知を引き出す心理的距離の設計が巧みだと思う。
- 一方で、DHDの構築にはAPIやクラウドサービス、長期の伴走支援が必要であり、一般の学校現場での再現性・スケーラビリティをどう担保するかが次の課題になりそう。
- 将来的には、より軽量な音声インターフェースやローカルモデルを使った簡易版DHDキットがあれば、クラブ活動や授業内でも「Reflecting with AI」を体験しやすくなりそうだと感じた。

# 次に読むべき論文は？
- OpenAI, "AI Safety via Debate"：AI同士の議論を用いて人間の判断を支援し、安全性と信頼性を高める枠組みを提案した先行研究。
- Noever et al., "Project Debater: A Large-Scale Argument Mining and Debate System"：人間とディベートするAIシステムのアーキテクチャと評価を詳細に報告したIBMの研究。
- Annapureddy et al., "A Framework of Generative AI Literacy Competencies"：本論文が参照する生成AIリテラシー12コンピテンシーの元になっている枠組み。

